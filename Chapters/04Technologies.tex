 \documentclass[../Main.tex]{subfiles}
\begin{document}

Today we have a great variety of free open-source tools for NN purposes and its
number is increasing with the growth of AI and ML. Development of neural networks,
mobile application or server is full of nuances, an unexperienced programmer may 
encounter many troubles since not everything can be easily tracked. However, most
problems can be resolved by good Internet research. Therefore, it is highly significant
to choose the up-to-date tools with well-prepared documentation and active communities. 
Technologies we have chosen allowed us to focus on core concepts instead of 
struggling with implementation or configuration.

\subsection{Neural Network}

    \subsubsection{PyTorch}
        \textbf{PyTorch} is an open-source machine learning library created by Facebook and broadly used in the field of computer vision. Released in 2016 rapidly gained popularity among researchers and developers. PyTorch is not another Python binding into a C++ framework. It uses core Python concepts like structures, classes or conditions, so integrates easily with the rest of Python ecosystem. Library provides all necessary tools for developing and training the neural networks based on deep learning models.
        
        Two main features of this package are:
        \begin{itemize}
            \item \textbf{Strong GPU acceleration} during computation of tensors
            \item Neural networks built on a tape-based \textbf{autograd system}
        \end{itemize}
        
        We decided to pick out PyTorch instead of TensorFlow (the main and actually the only alternative) due to several reasons. Firstly, TensorFlow was becoming more and more complex for machine learning beginners, where the PyTorch is based on basic and familiar programming paradigms. The new version of TF (2.0) solves this problem but was released after we had started working on the project. Moreover, the documentation is also pretty straightforward and helpful for newcomers. And finally, plenty of style transfer approaches are built on PyTorch. Including the network we adopt. 
%        \bartek{add biblio: https://pytorch.org/docs/stable/index.html}

    \subsubsection{CUDA}
    CUDA is parallel computing platform on GPUs and programming model created by NVIDIA. Using GPUs models can be train with shorter period of time and allow high floating-point computing performance.CUDA allows to use equivalent CPU functions for maximum use of GPUs and accelerate programms. Many frameworks like TensorFlow or PyTorch relay on CUDA for their GPU support. The NVIDIA company also created CUDA Toolkit, which includes libraries, debugging and optimalization tool, which support all NVIDIA GPUs. There are three main libraries intended for deep learning CuDNN, which is the most popular for deep neutral network computations and mostly using in open sorce frameworks, TensorRT - the high-performance inference optimalizer and runtime, and DeepStream, a liblary to video inference. You can use also use signal processing and math libraries. In case, when there are no needed library, you can write your low-level CUDA program in C or C++.  
%       \asia{add biblio: https://www.infoworld.com/article/3299703/what-is-cuda-parallel-programming-for-gpus.html, https://developer.nvidia.com/cuda-toolkit}
    
    \subsubsection{TensorRT} \label{trt_chapter}
    TensorRT is an SDK for deep learning interface \textbf{created by NVIDIA and designed for their GPUs}. It is built on CUDA and provides C++ and Python APIs, which allows loading pre-trained deep learning models, (trained with libraries like PyTorch) and run them on NVIDIA GPU. The main advantages of TensorRT are high-performance deep learning interface optimizer and light-weight runtime engine, that provide low latency and minimize streaming video delays. The engine is generated only once for each GPU and serialized as a plan file for the next uses. It is also possible to run an application with lower precision (if hardware allows doing so) to reduce memory requirements and reduce inference time. 
    
    The workflow of the build phase network on TensorRT follows those steps:
    \begin{itemize}
        \item Eliminate layers with unused outputs
        \item Eliminate operation equivalent to no-operation
        \item Fusion of convolution
        \item Aggregation of operations with similar parameters on the same source tensor 
        \item Merge of concatenation layers
        \item Modifies the precisions of weights 
        \item Calibration and appropriate scaling factors
        \item Run layers on dummy data, to chose the fastest kernel catalog
    \end{itemize}
    
    TensorRT allows focusing on creating new applications with AI, autonomous machines
    and high-performance computing instead of calibration for inference development.
    After optimization TensorRT chooses specific CUDA kernels for the platform to maximize
    performance on GPUs. It uses Docker for integration with DevOps architectures.
    
%        \asia{add biblio: https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide, https://developer.nvidia.com/tensorrt }

    \subsubsection{OpenCV}
    Open Source Computer Vision Library is an open-source library, orginaly developed by Intel, for computer vision and machine learning softwate. It includes dozens of computer vision algorithms adjusted for easy use for detect and recognize faces, identify objects and many others designed for image processing. Although written in C++, OpenCV has Python bindings and provides support for Machine Learning libraries like PyTorch.  By using it, one can process images and videos to detect objects, apply filters, analyze structure or perform reconstruction. OpenCV is designed to handle real-time vision applications and is currently developing full-featured CUDA interfaces.
%    \bartek{describe what do we use it for}
%    \bartek{add: https://docs.opencv.org/master/}


\newpage
\subsection{Server}
    Client-server communication is divided into two parts: video streaming and transferring filter specification data. The first part is maintained by a server in WebRTC standard, whereas the second one is micro-server based on Flask. Both segments are written in Python and developed by open-source communities.

    \subsubsection{WebRTC}
    WebRTC is an open framework that enables \textbf{Real Time Communication (RTC)} in web browsers and mobile apps via simple API. It provides tools to create peer-to-peer communication without any external plugins or programs. Standardized on API level by W3C 
    %\bartek{add hyperlink} 
    and protocol level by IETF 
    %\bartek{add hyperlink}
    is widely used and supported by Google, Apple, Microsoft, and main browser vendors. Given that our project and mobile application is cross-platfoom, we consider it as a key factor when choosing server technology.
    
    WebRTC architecture presented on  Figure \ref{fig:webrtc-public-diagram-for-website} contains two main layers: 
    \begin{itemize}
    \item C++ API - for browser makers implementing the Web API proposal
    \item Javascript Web API - for web developers building audio-video applications \\
    \end{itemize}
    
    \begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{webrtc-public-diagram-for-website}
    \caption{Overview of WebRTC architecture}
    \label{fig:webrtc-public-diagram-for-website}
    \end{figure}

    Comprehensive documentation and community creating many additional libraries make using this framework rather convenient. One of the most popular open-source libraries is \textbf{aiortc}.
    % \bartek{
    % photo: https://webrtc.org/architecture/
    % biblio: https://webrtc.org
    % }
    
    \subsubsection{Aiortc}
    \textbf{Aiortc} was developed as a 'WebRTC for Python'. Complexity (especially for beginners) and lack of Python bindings motivated authors of aiortc to design library and API which follow its Javascript counterpart. They pointed out that 
    %\bartek{add cite} 
    'WebRTC (...) is tightly coupled to a media stack, making it hard to plug in audio or video processing algorithms'. Our goal is to literally use the video processing algorithm, so we found this library and its examples extremely useful.
    We based our server on the aiortc example which performs video, audio and data channel establishing with a browser. It also allows pocessing streaming frames using OpenCV. 
        % \bartek{biblio: https://aiortc.readthedocs.io/en/stable/}
    
    \subsubsection{Flask}
    Flask is a so-called \textbf{micro-framework} with little dependencies to external libraries, which provides tools and technologies useful with building a small web application. It could be helpful for ones who want to create web pages, blogs or a simple REST server. 
    Technically, Flask is based on:
    \begin{itemize}
    \item Werkzeug WSGI (Web Server Gateway Interface is a popular specification for a universal interface between the  server and the web app) - toolkit which implements requests-response objects, and some service functions
    \item Jinja2 template engine - template system helpful with rendering dynamic web pages
    \end{itemize}
    Flask itself does not support database handling, validation or extensive visual templates. Being lightweight is the factor we found crucial, since our server does not perform any complicated tasks. Running constantly in the background, it only has to:
    \begin{itemize}
    \item Receive POST request from mobile application containing filter specification 
    \item Encode filter image and parameters
    \item Assign it to the IP of sender and store in particular folder
    \item Send confirmation response to the mobile app
    \end{itemize}
    We also decided to write simple Flask client in order to test connection to the server.
   % \bartek{biblio to add: http://flask.palletsprojects.com/en/1.1.x/}
    
    \subsubsection{Server flow}
    The aforementioned servers work separately and do not directly interfere with each other and could perform tasks asynchronously. In that way, many clients can upload filter images and parameters as well as stream video without delays. Every client can change filter params and start a new stream in various order, but the usual client-server flow is depicted in Figure \ref{fig:server-flow} \\
    \begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{server-flow}
    \caption{Client-server flow}
        \label{fig:server-flow}
    \end{figure}
    
    In a nutshell, when user selects filter style the following actions happen:
    \begin{enumerate}
    \item Mobile app send POST request to the Flask server running on port 5000 including JSON with three fields: filter image encoded in base64 format, filter benchmark value in float, boolean information about color preservation during process 
    \item Flask server performs tasks described in the section 5.2.3
    \item Mobile app ping server running on port 8080
    \item Server establishes RTC-peer connection with browser running inside app
    \item The stream is started - aiortc-based server catch frame and transform it using filter style image uploaded in advance from storage
    \item Transformed frame is added to RTC Media Stream Track and streamed back to the mobile browser
    \item Browser displays video using WebView component 
    \end{enumerate}
    
    When streaming finishes or breaks (due to network error, application shutdown or any other error), server close connection gracefully but still stores last filter style parameters. If they are not specified during the next stream or the POST request to the Flask server fails, the server uses saved ones. 
    
    \subsubsection{Alternative technologies}
    We had been trying several options before we chose to use aiortc. Our prime attempt was to adopt \textit{WebRTC Plugin for Flutter}. It is a small project developed by the Flutter community containing Javascript server and Flutter client. That seemed to be a perfect solution that could accelerate our work.
    However, we encounter some obstacles in this undertaking. First of all, the mentioned plugin is poorly documented and error-prone what is a rather annoying combination. Secondly, it works efficiently only over the LAN network when we wish to connect to the server from any place. And the third thing is the communication crashes if the video is not streaming to/from the Chrome browser. Nevertheless, the project is gathering greater community what makes it promising in the time of growing popularity of Flutter.
    %\bartek{biblio to add:  https://github.com/cloudwebrtc/flutter-webrtc}
   
\newpage
\subsection{Mobile Application}
    This part describes the main technology used in clinet application which is Flutter. 
    We will also explain why we've chosen this specific technology.. 
    \subsubsection{Flutter}
        Today there are several frameworks which allow us to create mobile 
        applications for both Android and iOS simultaneously, 
        eg. React Native, Ionic, Xamarin.
        In 2015 Flutter joined this family and changed drastically situation
        on mobile application scene. At the moment when we write this paper,
        Flutter is the most popular multiplatform framework, which allow us to 
        create not only mobile applications but also web from single codebase.
    
    
        Flutter is framework created by Google but it's also an open source project 
        so everyone can propose new features and improvments. 
        When we write Flutter application we use Dart - language developed by 
        Google with C-style syntax.
        It runs on Dart VM included in the SDK. 
        Very interesting feature of Dart is that it optionally transcompiles to 
        JavaScript so you can also create web applications.
        
        
        Basic idea of Flutter sounds "Everythingâ€™s a widget" and widgets are 
        quite similar to React "components". 
        Widgets can be combined in order to create more complex ones. 
        You use widgets to build whole UI and some of them are:
        \begin{itemize}
            \item Layout widgets - e.g. rows, columns, lists, grids, tables
            \item Style widgets - e.g. colors, fonts
            \item Structure widgets - e.g. buttons, sliders, switches
            \item Animation widgets - e.g. transition, fade in
        \end{itemize}
        Flutter comes with loads of prebuilt Material Design and Cupertino(iOS style)
        widgets which makes easy and fast to create great looking applications. 
        There are Material Design icons, colors, typical UI interface 
        elements like top and bottom bars, buttons, list, animations and much more.
        
        
        Widgets are split into two main categories:
        \begin{itemize}
             \item Stateless - build only when the input data changes. 
             \item Statefull - build when input data or state property changes 
        \end{itemize}
        Difference between this two kinds of widgets is that Stateless widgets 
        never changes while Statefull can be modified during their lifetime.
        One example of statefull widget is simple checkbox. When we press checkbox
        it changes it's state to checked or unchecked and triggers rebuild on itself.
        When we want change state of widget we must use special 
        \textit{setState} to made flutter to re render this particular widget.
    
        
        Flutter architecture is composed of many layers but we can split it into 
        three main layers presented at Figure \ref{fig:flutter-layers}.
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.80\textwidth]{flutter-system.jpeg}
            \caption{Flutter layers}
            \label{fig:flutter-layers}
        \end{figure}
        Programmers have more contact with top layers of framework - 
        these are Material and Cupertino widgets which are composed of basic widgets.
        Basic widgets uses lower layers of framework. 
        The lowest one is foundation which contains core classes, functions and constants.
    
    
        From the beginning of our project we wanted to be able to develop new ideas
        very quickly.
        Python and PyTorch are technologies which definitely helped us keep high
        productivity during this time. First choose was Kotlin - new modern programing 
        language for Android applications. Main advantages of Kotlin are:
            \begin{itemize}
                \item official supported by Google
                \item high performance - native application
                \item some great language features like null safety, readability or async functions
                \item we had some experience with this language
            \end{itemize}
            
        The main drawback of creating mobile applications with Kotlin is that creating
        some simple things can often take much time and effort. 
        This was a main cause of rejecting this approach.
        We've looked for some other tools to create our client application and 
        we've found Flutter - relatively new tool framework from Google which 
        is still developing very quickly.
        The main advantage of Flutter is that you can develop your apps very 
        quickly because there are tons of ready, efficient and highly customizable 
        widgets. There is also large community which creates new great widgets 
        add publishes them on official website so everyone can download them and use in project.
        You can also modify or build new widgets on top of it and then publish.
        If some widget would become very popular and useful it will may be 
        include to official Flutter SDK. 
        Flutter also makes easy to create apps in beautiful Mateterial Design 
        style or it's iOS equivalent - Cupertino. 
        The main feature of Flutter, and always mentioned by Google is of course 
        creating applications for Android and iOS at the same time. 
        Our main goal was to create application for Android so we treated this feature like 
        an opened door. 
        Flutter is also declarative, react style framework which we prefer while
        creating user interface's. We've had previous experience with React on web
        so Flutter seemed easy to learn. 
    

\biblio % Needed for referencing to working when compiling individual subfiles - Do not remove
\end{document}

