\documentclass[../Main.tex]{subfiles}
\begin{document}

We consider style transfer algorithm for processing video. 
To improve available algorithm, we focus on minimizing inference time by
network pruning and use of specialized inference libraries. We arrive at an algorithm, 
which runs with satisfying resolution of images in real time even on middle-range
NVIDIA 900 series GPUs. For client we prepare mobile application and server to communication.

Gatys et al. recently introduced a neural algorithm that
renders a content image in the style of another image,
achieving so-called style transfer. However, their framework requires a slow iterative optimization process, which
limits its practical application. Fast approximations with
feed-forward neural networks have been proposed to speed
up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed
set of styles and cannot adapt to arbitrary new styles. In this
paper, we present a simple yet effective approach that for the
first time enables arbitrary style transfer in real-time. At the
heart of our method is a novel adaptive instance normalization (AdaIN) layer that aligns the mean and variance of the
content features with those of the style features. Our method
achieves speed comparable to the fastest existing approach,
without the restriction to a pre-defined set of styles. In addition, our approach allows flexible user controls such as
content-style trade-off, style interpolation, color \& spatial
controls, all using a single feed-forward neural network

\par\vspace*{\fill} % Moves keywords to the bottom of the page


\biblio % Needed for referencing to working when compiling individual subfiles - Do not remove
\end{document}
